#!/usr/bin/env python3
"""
–û—Ç–ª–∞–¥–æ—á–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã AppExchange
"""

import requests
from bs4 import BeautifulSoup
import re

def analyze_page_structure(url):
    """–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
    print(f"üîç –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {url}")
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        print(f"‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ (—Ä–∞–∑–º–µ—Ä: {len(response.text):,} —Å–∏–º–≤–æ–ª–æ–≤)")
        
        # –ü–æ–∏—Å–∫ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        print("\nüîç –ü–æ–∏—Å–∫ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ (h1, h2, h3):")
        for tag in ['h1', 'h2', 'h3']:
            elements = soup.find_all(tag)
            for i, elem in enumerate(elements[:5]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
                text = elem.get_text().strip()[:100]
                print(f"   {tag.upper()} #{i+1}: {text}")
        
        # –ü–æ–∏—Å–∫ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å –∫–ª–∞—Å—Å–∞–º–∏, —Å–æ–¥–µ—Ä–∂–∞—â–∏–º–∏ 'title'
        print("\nüîç –≠–ª–µ–º–µ–Ω—Ç—ã —Å –∫–ª–∞—Å—Å–∞–º–∏ —Å–æ–¥–µ—Ä–∂–∞—â–∏–º–∏ 'title':")
        title_elements = soup.find_all(attrs={'class': re.compile(r'title', re.I)})
        for i, elem in enumerate(title_elements[:10]):
            classes = ' '.join(elem.get('class', []))
            text = elem.get_text().strip()[:100]
            print(f"   #{i+1} .{classes}: {text}")
        
        # –ü–æ–∏—Å–∫ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å –∫–ª–∞—Å—Å–∞–º–∏, —Å–æ–¥–µ—Ä–∂–∞—â–∏–º–∏ 'listing'
        print("\nüîç –≠–ª–µ–º–µ–Ω—Ç—ã —Å –∫–ª–∞—Å—Å–∞–º–∏ —Å–æ–¥–µ—Ä–∂–∞—â–∏–º–∏ 'listing':")
        listing_elements = soup.find_all(attrs={'class': re.compile(r'listing', re.I)})
        for i, elem in enumerate(listing_elements[:10]):
            classes = ' '.join(elem.get('class', []))
            text = elem.get_text().strip()[:100]
            print(f"   #{i+1} .{classes}: {text}")
        
        # –ü–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        print("\nüîç –ü–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:")
        images = soup.find_all('img')
        for i, img in enumerate(images[:10]):
            classes = ' '.join(img.get('class', []))
            src = img.get('src', '')[:100]
            alt = img.get('alt', '')[:50]
            print(f"   IMG #{i+1}: class='{classes}' src='{src}' alt='{alt}'")
        
        # –ü–æ–∏—Å–∫ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å 'By' –≤ —Ç–µ–∫—Å—Ç–µ
        print("\nüîç –≠–ª–µ–º–µ–Ω—Ç—ã —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ 'By' –≤ —Ç–µ–∫—Å—Ç–µ:")
        by_elements = soup.find_all(string=re.compile(r'By\s+', re.I))
        for i, text in enumerate(by_elements[:5]):
            parent = text.parent
            classes = ' '.join(parent.get('class', [])) if parent.get('class') else 'no-class'
            print(f"   #{i+1} .{classes}: {text.strip()}")
        
        # OpenGraph –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        print("\nüîç OpenGraph –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ:")
        og_tags = soup.find_all('meta', property=re.compile(r'^og:'))
        for tag in og_tags:
            property_name = tag.get('property')
            content = tag.get('content', '')[:100]
            print(f"   {property_name}: {content}")
        
        # –ü–æ–∏—Å–∫ —Å–∫—Ä–∏–ø—Ç–æ–≤ —Å JSON –¥–∞–Ω–Ω—ã–º–∏
        print("\nüîç –ü–æ–∏—Å–∫ JSON –¥–∞–Ω–Ω—ã—Ö –≤ —Å–∫—Ä–∏–ø—Ç–∞—Ö:")
        scripts = soup.find_all('script', type='application/json')
        for i, script in enumerate(scripts[:3]):
            content = script.get_text()[:200]
            print(f"   JSON #{i+1}: {content}...")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")
        return False

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞"""
    print("=" * 80)
    print("üïµÔ∏è –û—Ç–ª–∞–¥–∫–∞ –ø–∞—Ä—Å–µ—Ä–∞ AppExchange - –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã HTML")
    print("=" * 80)
    
    # –¢–µ—Å—Ç–æ–≤—ã–π URL
    test_url = 'https://appexchange.salesforce.com/appxListingDetail?listingId=a0N3000000B4cKBEAZ'
    
    analyze_page_structure(test_url)

if __name__ == '__main__':
    main()