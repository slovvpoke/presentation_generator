"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä AppExchange —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
============================================================

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å —Ä–∞—Å—à–∏—Ä—è–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞, –¥–æ–±–∞–≤–ª—è—è:
- –ü–æ–¥–¥–µ—Ä–∂–∫—É –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∂–∞–µ–º–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —á–µ—Ä–µ–∑ Selenium
- –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
- –õ—É—á—à—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫
"""

import os
import time
from typing import Optional, Tuple
from dataclasses import dataclass

import requests
from bs4 import BeautifulSoup
from PIL import Image
from io import BytesIO

# –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∏–º–ø–æ—Ä—Ç Selenium
try:
    from selenium import webdriver
    from selenium.webdriver.chrome.service import Service
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from webdriver_manager.chrome import ChromeDriverManager
    SELENIUM_AVAILABLE = True
except ImportError:
    SELENIUM_AVAILABLE = False

from sfapps_template_generator import AppMetadata


class EnhancedAppExchangeParser:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –¥–ª—è AppExchange —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü"""
    
    def __init__(self, use_selenium=False, headless=True):
        self.use_selenium = use_selenium and SELENIUM_AVAILABLE
        self.headless = headless
        self.driver = None
        
        # –ó–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è HTTP –∑–∞–ø—Ä–æ—Å–æ–≤
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
    
    def __enter__(self):
        if self.use_selenium:
            self._setup_driver()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.driver:
            self.driver.quit()
    
    def _setup_driver(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ Selenium WebDriver"""
        if not SELENIUM_AVAILABLE:
            raise ImportError("Selenium –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install selenium webdriver-manager")
        
        try:
            options = Options()
            if self.headless:
                options.add_argument('--headless')
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-gpu')
            options.add_argument('--window-size=1920,1080')
            options.add_argument(f'--user-agent={self.headers["User-Agent"]}')
            
            service = Service(ChromeDriverManager().install())
            self.driver = webdriver.Chrome(service=service, options=options)
            self.driver.set_page_load_timeout(30)
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ WebDriver: {e}")
            self.driver = None
            self.use_selenium = False
    
    def fetch_page_content(self, url: str, timeout: int = 20) -> Optional[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        
        if self.use_selenium and self.driver:
            try:
                print(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Selenium –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏: {url}")
                self.driver.get(url)
                
                # –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                WebDriverWait(self.driver, 10).until(
                    EC.presence_of_element_located((By.TAG_NAME, "body"))
                )
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø–∞—É–∑–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                time.sleep(3)
                
                return self.driver.page_source
                
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ Selenium: {e}, –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ requests")
        
        # Fallback –Ω–∞ –æ–±—ã—á–Ω—ã–π HTTP –∑–∞–ø—Ä–æ—Å
        try:
            print(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ requests –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏: {url}")
            response = requests.get(url, headers=self.headers, timeout=timeout)
            response.raise_for_status()
            return response.text
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ HTTP –∑–∞–ø—Ä–æ—Å–∞: {e}")
            return None
    
    def extract_app_metadata(self, html: str) -> Tuple[Optional[str], Optional[str], Optional[str]]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –∏–∑ HTML"""
        soup = BeautifulSoup(html, 'html.parser')
        name = None
        developer = None
        logo_url = None
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: CSS —Å–µ–ª–µ–∫—Ç–æ—Ä—ã (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è)
        name, developer, logo_url = self._extract_from_css_selectors(soup)
        print(f"CSS —Å–µ–ª–µ–∫—Ç–æ—Ä—ã: name='{name}', developer='{developer}', logo_url='{logo_url}'")
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: –ü–æ–∏—Å–∫ –≤ JSON –¥–∞–Ω–Ω—ã—Ö (–µ—Å–ª–∏ CSS –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª)
        if not all([name, developer, logo_url]):
            name2, developer2, logo_url2 = self._extract_from_json(soup)
            name = name or name2
            developer = developer or developer2
            logo_url = logo_url or logo_url2
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 3: OpenGraph –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (—Ñ–∏–Ω–∞–ª—å–Ω—ã–π fallback)
        if not all([name, developer, logo_url]):
            name3, developer3, logo_url3 = self._extract_from_meta_tags(soup)
            name = name or name3
            developer = developer or developer3
            logo_url = logo_url or logo_url3
        
        return name, developer, logo_url
    
    def _extract_from_json(self, soup) -> Tuple[Optional[str], Optional[str], Optional[str]]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ JSON —Å–∫—Ä–∏–ø—Ç–æ–≤"""
        import json
        import re
        
        name = None
        developer = None
        logo_url = None
        
        # –ü–æ–∏—Å–∫ –≤ script —Ç–µ–≥–∞—Ö —Å application/json
        script_tags = soup.find_all('script', type='application/json')
        for script in script_tags:
            try:
                data = json.loads(script.get_text())
                name, developer, logo_url = self._search_json_data(data)
                if name and developer:
                    break
            except:
                continue
        
        # –ü–æ–∏—Å–∫ –≤ –æ–±—ã—á–Ω—ã—Ö script —Ç–µ–≥–∞—Ö —Å JSON –¥–∞–Ω–Ω—ã–º–∏
        if not name:
            script_tags = soup.find_all('script')
            for script in script_tags:
                text = script.get_text()
                # –ü–æ–∏—Å–∫ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ JSON –≤ JavaScript
                json_patterns = [
                    r'window\.__INITIAL_STATE__\s*=\s*({.+?});',
                    r'window\.__APP_DATA__\s*=\s*({.+?});',
                    r'__NEXT_DATA__\s*=\s*({.+?})',
                    r'window\.pageData\s*=\s*({.+?});'
                ]
                
                for pattern in json_patterns:
                    match = re.search(pattern, text, re.DOTALL)
                    if match:
                        try:
                            data = json.loads(match.group(1))
                            name, developer, logo_url = self._search_json_data(data)
                            if name and developer:
                                break
                        except:
                            continue
                if name and developer:
                    break
        
        return name, developer, logo_url
    
    def _search_json_data(self, data, depth=0, max_depth=5):
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –≤ JSON —Å—Ç—Ä—É–∫—Ç—É—Ä–µ"""
        if depth > max_depth or not isinstance(data, (dict, list)):
            return None, None, None
        
        if isinstance(data, dict):
            # –ü–æ–∏—Å–∫ –ø—Ä—è–º—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
            if 'name' in data and 'publisher' in data:
                return data.get('name'), data.get('publisher'), data.get('logoUrl') or data.get('logo')
            
            if 'title' in data and 'developer' in data:
                return data.get('title'), data.get('developer'), data.get('imageUrl') or data.get('image')
            
            # –ü–æ–∏—Å–∫ –≤ –ø–æ–¥–æ–±—ä–µ–∫—Ç–∞—Ö
            for key, value in data.items():
                if isinstance(value, (dict, list)):
                    name, dev, logo = self._search_json_data(value, depth + 1, max_depth)
                    if name and dev:
                        return name, dev, logo
        
        elif isinstance(data, list):
            for item in data:
                name, dev, logo = self._search_json_data(item, depth + 1, max_depth)
                if name and dev:
                    return name, dev, logo
        
        return None, None, None
    
    def _extract_from_css_selectors(self, soup) -> Tuple[Optional[str], Optional[str], Optional[str]]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ CSS —Å–µ–ª–µ–∫—Ç–æ—Ä—ã"""
        name = None
        developer = None
        logo_url = None
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –Ω–∞–∑–≤–∞–Ω–∏—è
        name_selectors = [
            '.listing-title h1',
            'h1[data-test-id="listing-title"]',
            'h1.listing-header__title',
            '[data-testid="listing-title"]',
            '.app-title',
            '.listing-name',
            '.page-header h1',
            '.solution-title',
            '[data-cy="listing-title"]'
        ]
        
        for selector in name_selectors:
            element = soup.select_one(selector)
            if element:
                text = element.get_text().strip()
                if text:  # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ —Ç–µ–∫—Å—Ç –Ω–µ –ø—É—Å—Ç–æ–π
                    name = text
                    print(f"–ù–∞–π–¥–µ–Ω–æ –Ω–∞–∑–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ —Å–µ–ª–µ–∫—Ç–æ—Ä '{selector}': {name}")
                    break
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞
        dev_selectors = [
            '.listing-title p',
            '[data-test-id="listing-publisher"]',
            '.listing-header__publisher',
            '[data-testid="listing-publisher"]',
            '.app-publisher',
            '.listing-publisher',
            '.publisher-name',
            '.solution-publisher',
            '[data-cy="listing-publisher"]'
        ]
        
        for selector in dev_selectors:
            element = soup.select_one(selector)
            if element:
                dev_text = element.get_text().strip()
                if dev_text:  # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ —Ç–µ–∫—Å—Ç –Ω–µ –ø—É—Å—Ç–æ–π
                    if dev_text.lower().startswith('by '):
                        developer = dev_text[3:].strip()
                    else:
                        developer = dev_text
                    print(f"–ù–∞–π–¥–µ–Ω —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫ —á–µ—Ä–µ–∑ —Å–µ–ª–µ–∫—Ç–æ—Ä '{selector}': {developer}")
                    break
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –ª–æ–≥–æ—Ç–∏–ø–∞
        logo_selectors = [
            '.summary .listing-logo .ads-image',
            '[data-test-id="listing-logo"] img',
            '.listing-header__logo img',
            '[data-testid="listing-logo"] img',
            '.app-logo img',
            '.listing-logo img',
            '.solution-logo img',
            '.publisher-logo img',
            '[data-cy="listing-logo"] img'
        ]
        
        for selector in logo_selectors:
            element = soup.select_one(selector)
            if element:
                logo_url = (element.get('src') or 
                           element.get('data-src') or 
                           element.get('data-original') or 
                           element.get('data-lazy') or
                           element.get('data-srcset', '').split(',')[0].strip().split(' ')[0])
                if logo_url:
                    print(f"–ù–∞–π–¥–µ–Ω –ª–æ–≥–æ—Ç–∏–ø —á–µ—Ä–µ–∑ —Å–µ–ª–µ–∫—Ç–æ—Ä '{selector}': {logo_url}")
                    break
        
        return name, developer, logo_url
    
    def _extract_from_meta_tags(self, soup) -> Tuple[Optional[str], Optional[str], Optional[str]]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –º–µ—Ç–∞-—Ç–µ–≥–æ–≤"""
        name = None
        developer = None
        logo_url = None
        
        # OpenGraph –∑–∞–≥–æ–ª–æ–≤–æ–∫
        og_title = soup.find('meta', property='og:title')
        if og_title and og_title.get('content'):
            title_content = og_title['content']
            if '|' in title_content:
                name = title_content.split('|')[0].strip()
            else:
                name = title_content.strip()
        
        # OpenGraph –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        og_image = soup.find('meta', property='og:image')
        if og_image and og_image.get('content'):
            logo_url = og_image['content']
        
        # Twitter –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞
        twitter_data1 = soup.find('meta', attrs={'name': 'twitter:data1'})
        if twitter_data1 and twitter_data1.get('content'):
            developer = twitter_data1['content'].strip()
        
        # –ü–æ–∏—Å–∫ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        if not developer:
            description = soup.find('meta', attrs={'name': 'description'})
            if description and description.get('content'):
                desc_text = description['content']
                # –ü–æ–∏—Å–∫ –ø–∞—Ç—Ç–µ—Ä–Ω–∞ "By Company Name"
                import re
                by_match = re.search(r'By\s+([^,\.\|]+)', desc_text, re.IGNORECASE)
                if by_match:
                    developer = by_match.group(1).strip()
        
        return name, developer, logo_url
    
    def fetch_app_metadata(self, url: str, timeout: int = 20) -> Optional[AppMetadata]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ª–Ω—ã—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
        try:
            # –ü–æ–ª—É—á–µ–Ω–∏–µ HTML –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            html = self.fetch_page_content(url, timeout)
            if not html:
                return None
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
            name, developer, logo_url = self.extract_app_metadata(html)
            
            if not name:
                print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è")
                return None
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ –ª–æ–≥–æ—Ç–∏–ø–∞
            logo_bytes = b''
            logo_mime = 'image/png'
            
            if logo_url:
                try:
                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö URL
                    if logo_url.startswith('//'):
                        logo_url = 'https:' + logo_url
                    elif logo_url.startswith('/'):
                        from urllib.parse import urljoin, urlparse
                        base_url = f"{urlparse(url).scheme}://{urlparse(url).netloc}"
                        logo_url = urljoin(base_url, logo_url)
                    
                    print(f"–ó–∞–≥—Ä—É–∑–∫–∞ –ª–æ–≥–æ—Ç–∏–ø–∞: {logo_url}")
                    logo_response = requests.get(logo_url, headers=self.headers, timeout=10)
                    logo_response.raise_for_status()
                    
                    logo_bytes = logo_response.content
                    logo_mime = logo_response.headers.get('Content-Type', 'image/png')
                    
                    # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                    try:
                        with Image.open(BytesIO(logo_bytes)) as img:
                            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ (–∏–∑–±–µ–≥–∞–µ–º —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)
                            if img.width < 10 or img.height < 10:
                                print(f"–õ–æ–≥–æ—Ç–∏–ø —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π: {img.width}x{img.height}")
                                logo_bytes = b''
                    except Exception as e:
                        print(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
                        logo_bytes = b''
                        
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ª–æ–≥–æ—Ç–∏–ø–∞: {e}")
            
            return AppMetadata(
                url=url,
                name=name or 'Unknown App',
                developer=developer or 'Unknown Developer',
                logo_bytes=logo_bytes,
                logo_mime=logo_mime
            )
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {e}")
            return None


# –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–º–µ–Ω—ã –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π
def enhanced_fetch_app_metadata(url: str, timeout: int = 20, use_selenium: bool = False) -> Optional[AppMetadata]:
    """
    –£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è fetch_app_metadata —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
    
    Parameters
    ----------
    url: str
        URL AppExchange —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    timeout: int
        –¢–∞–π–º–∞—É—Ç –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤
    use_selenium: bool
        –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ Selenium –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
    
    Returns
    -------
    AppMetadata or None
    """
    with EnhancedAppExchangeParser(use_selenium=use_selenium) as parser:
        return parser.fetch_app_metadata(url, timeout)


if __name__ == '__main__':
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞
    test_urls = [
        'https://appexchange.salesforce.com/appxListingDetail?listingId=a0N3000000B4cKBEAZ',
        'https://appexchange.salesforce.com/appxListingDetail?listingId=a0N3u00000MSfukEAD'
    ]
    
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞")
    print("=" * 50)
    
    for i, url in enumerate(test_urls, 1):
        print(f"\nüìã –¢–µ—Å—Ç {i}: {url}")
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –±–µ–∑ Selenium
        print("\nüîÑ –¢–µ—Å—Ç –±–µ–∑ Selenium:")
        metadata = enhanced_fetch_app_metadata(url, use_selenium=False)
        if metadata:
            print(f"‚úÖ –ù–∞–∑–≤–∞–Ω–∏–µ: {metadata.name}")
            print(f"‚úÖ –†–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫: {metadata.developer}")
            print(f"‚úÖ –õ–æ–≥–æ—Ç–∏–ø: {len(metadata.logo_bytes)} –±–∞–π—Ç")
        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ")
        
        # –ó–∞—Ç–µ–º –ø—Ä–æ–±—É–µ–º —Å Selenium (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
        if SELENIUM_AVAILABLE:
            print("\nü§ñ –¢–µ—Å—Ç —Å Selenium:")
            metadata = enhanced_fetch_app_metadata(url, use_selenium=True)
            if metadata:
                print(f"‚úÖ –ù–∞–∑–≤–∞–Ω–∏–µ: {metadata.name}")
                print(f"‚úÖ –†–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫: {metadata.developer}")
                print(f"‚úÖ –õ–æ–≥–æ—Ç–∏–ø: {len(metadata.logo_bytes)} –±–∞–π—Ç")
            else:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ")
        else:
            print("\n‚ö†Ô∏è Selenium –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")